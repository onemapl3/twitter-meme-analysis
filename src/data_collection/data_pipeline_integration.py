#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®ç®¡é“é›†æˆè„šæœ¬
å®ç°ä»CSVæ–‡ä»¶è¯»å–åˆ°å®æ—¶APIé‡‡é›†çš„å¹³æ»‘åˆ‡æ¢
"""

import json
import logging
import pandas as pd
import psycopg2
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import hashlib

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class DataPipelineIntegrator:
    """æ•°æ®ç®¡é“é›†æˆå™¨"""
    
    def __init__(self, config_file='collector_config.json'):
        """åˆå§‹åŒ–é›†æˆå™¨"""
        self.config = self._load_config(config_file)
        self.db_config = self.config['database']
        self.db_conn = None
        
    def _load_config(self, config_file):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            logger.error(f"é…ç½®æ–‡ä»¶ {config_file} æœªæ‰¾åˆ°")
            raise
    
    def connect_database(self):
        """è¿æ¥æ•°æ®åº“"""
        try:
            self.db_conn = psycopg2.connect(
                host=self.db_config['host'],
                port=self.db_config['port'],
                database=self.db_config['database'],
                user=self.db_config['user'],
                password=self.db_config['password']
            )
            logger.info("æ•°æ®åº“è¿æ¥æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            return False
    
    def migrate_csv_data(self):
        """è¿ç§»CSVæ•°æ®åˆ°æ•°æ®åº“"""
        print("ğŸ”„ å¼€å§‹è¿ç§»CSVæ•°æ®åˆ°æ•°æ®åº“...")
        
        if not self.connect_database():
            return False
        
        try:
            # è¿ç§»æ¨æ–‡æ•°æ®
            tweets_migrated = self._migrate_tweets()
            
            # è¿ç§»ç”¨æˆ·å…³ç³»æ•°æ®
            users_migrated = self._migrate_users()
            
            # è¿ç§»KOLæ¡£æ¡ˆæ•°æ®
            kol_profiles_migrated = self._migrate_kol_profiles()
            
            print(f"âœ… æ•°æ®è¿ç§»å®Œæˆï¼")
            print(f"  - æ¨æ–‡: {tweets_migrated} æ¡")
            print(f"  - ç”¨æˆ·: {users_migrated} ä¸ª")
            print(f"  - KOLæ¡£æ¡ˆ: {kol_profiles_migrated} ä¸ª")
            
            return True
            
        except Exception as e:
            logger.error(f"æ•°æ®è¿ç§»å¤±è´¥: {e}")
            return False
        finally:
            if self.db_conn:
                self.db_conn.close()
    
    def _migrate_tweets(self) -> int:
        """è¿ç§»æ¨æ–‡æ•°æ®"""
        print("  ğŸ“ è¿ç§»æ¨æ–‡æ•°æ®...")
        
        try:
            # è¯»å–CSVæ–‡ä»¶
            from config.paths import TWEETS_FILE
            tweets_df = pd.read_csv(TWEETS_FILE)
            print(f"    è¯»å–åˆ° {len(tweets_df)} æ¡æ¨æ–‡")
            
            cursor = self.db_conn.cursor()
            
            # æ¸…ç©ºç°æœ‰æ•°æ®
            cursor.execute("DELETE FROM tweets")
            print("    æ¸…ç©ºç°æœ‰æ¨æ–‡æ•°æ®")
            
            # æ‰¹é‡æ’å…¥æ•°æ®
            batch_size = 1000
            migrated_count = 0
            
            for i in range(0, len(tweets_df), batch_size):
                batch = tweets_df.iloc[i:i+batch_size]
                
                for _, row in batch.iterrows():
                    try:
                        # æå–memeæåŠ
                        meme_mentions = self._extract_meme_mentions(row.get('text', ''))
                        
                        # è®¡ç®—äº’åŠ¨æŒ‡æ ‡
                        engagement_metrics = {
                            'likes': int(row.get('likes', 0)),
                            'retweets': int(row.get('retweets', 0)),
                            'replies': int(row.get('replies', 0)),
                            'quotes': int(row.get('quotes', 0))
                        }
                        
                        # æ’å…¥æ•°æ®
                        cursor.execute("""
                            INSERT INTO tweets (
                                tweet_id, text, user_id, username, created_at,
                                retweet_count, like_count, reply_count, quote_count,
                                hashtags, mentions, meme_mentions, engagement_metrics,
                                collected_at
                            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                        """, (
                            str(row.get('tweet_id', '')),
                            str(row.get('text', '')),
                            str(row.get('user_id', '')),
                            str(row.get('username', '')),
                            row.get('created_at', datetime.now()),
                            int(row.get('retweets', 0)),
                            int(row.get('likes', 0)),
                            int(row.get('replies', 0)),
                            int(row.get('quotes', 0)),
                            [],  # hashtags
                            [],  # mentions
                            meme_mentions,
                            json.dumps(engagement_metrics),
                            datetime.now()
                        ))
                        
                        migrated_count += 1
                        
                    except Exception as e:
                        logger.warning(f"è·³è¿‡æ— æ•ˆæ¨æ–‡æ•°æ®: {e}")
                        continue
                
                # æäº¤æ‰¹æ¬¡
                self.db_conn.commit()
                print(f"    å·²è¿ç§» {migrated_count} æ¡æ¨æ–‡")
            
            cursor.close()
            return migrated_count
            
        except Exception as e:
            logger.error(f"æ¨æ–‡æ•°æ®è¿ç§»å¤±è´¥: {e}")
            return 0
    
    def _migrate_users(self) -> int:
        """è¿ç§»ç”¨æˆ·æ•°æ®"""
        print("  ğŸ‘¥ è¿ç§»ç”¨æˆ·æ•°æ®...")
        
        try:
            # è¯»å–CSVæ–‡ä»¶
            from config.paths import FOLLOWINGS_FILE
            followings_df = pd.read_csv(FOLLOWINGS_FILE)
            print(f"    è¯»å–åˆ° {len(followings_df)} æ¡ç”¨æˆ·å…³ç³»")
            
            cursor = self.db_conn.cursor()
            
            # æ¸…ç©ºç°æœ‰æ•°æ®
            cursor.execute("DELETE FROM kol_users")
            print("    æ¸…ç©ºç°æœ‰ç”¨æˆ·æ•°æ®")
            
            # æå–å”¯ä¸€ç”¨æˆ·
            unique_users = followings_df[['user_id', 'username']].drop_duplicates()
            migrated_count = 0
            
            for _, row in unique_users.iterrows():
                try:
                    # è®¡ç®—KOLåˆ†æ•°ï¼ˆç®€åŒ–ç‰ˆï¼‰
                    kol_score = self._calculate_kol_score(row)
                    kol_tier = self._determine_kol_tier(kol_score)
                    
                    cursor.execute("""
                        INSERT INTO kol_users (
                            user_id, username, display_name, kol_score, kol_tier,
                            profile_data, last_updated
                        ) VALUES (%s, %s, %s, %s, %s, %s, %s)
                    """, (
                        str(row.get('user_id', '')),
                        str(row.get('username', '')),
                        str(row.get('username', '')),
                        kol_score,
                        kol_tier,
                        json.dumps({'source': 'csv_migration'}),
                        datetime.now()
                    ))
                    
                    migrated_count += 1
                    
                except Exception as e:
                    logger.warning(f"è·³è¿‡æ— æ•ˆç”¨æˆ·æ•°æ®: {e}")
                    continue
            
            self.db_conn.commit()
            cursor.close()
            
            print(f"    å·²è¿ç§» {migrated_count} ä¸ªç”¨æˆ·")
            return migrated_count
            
        except Exception as e:
            logger.error(f"ç”¨æˆ·æ•°æ®è¿ç§»å¤±è´¥: {e}")
            return 0
    
    def _migrate_kol_profiles(self) -> int:
        """è¿ç§»KOLæ¡£æ¡ˆæ•°æ®"""
        print("  ğŸ“‹ è¿ç§»KOLæ¡£æ¡ˆæ•°æ®...")
        
        try:
            # è¯»å–JSONæ–‡ä»¶
            from config.paths import KOL_PROFILES_FILE
            with open(KOL_PROFILES_FILE, 'r', encoding='utf-8') as f:
                kol_data = json.load(f)
            
            if 'kol_profiles' not in kol_data:
                print("    æœªæ‰¾åˆ°KOLæ¡£æ¡ˆæ•°æ®")
                return 0
            
            kol_profiles = kol_data['kol_profiles']
            print(f"    è¯»å–åˆ° {len(kol_profiles)} ä¸ªKOLæ¡£æ¡ˆ")
            
            cursor = self.db_conn.cursor()
            migrated_count = 0
            
            for profile in kol_profiles:
                try:
                    user_id = profile.get('user_id', '')
                    if not user_id:
                        continue
                    
                    # æ›´æ–°ç°æœ‰ç”¨æˆ·è®°å½•
                    cursor.execute("""
                        UPDATE kol_users 
                        SET kol_score = %s, kol_tier = %s, profile_data = %s, last_updated = %s
                        WHERE user_id = %s
                    """, (
                        float(profile.get('kol_score', 0)),
                        str(profile.get('kol_tier', 'Tier 4')),
                        json.dumps(profile),
                        datetime.now(),
                        str(user_id)
                    ))
                    
                    if cursor.rowcount > 0:
                        migrated_count += 1
                    
                except Exception as e:
                    logger.warning(f"è·³è¿‡æ— æ•ˆKOLæ¡£æ¡ˆ: {e}")
                    continue
            
            self.db_conn.commit()
            cursor.close()
            
            print(f"    å·²æ›´æ–° {migrated_count} ä¸ªKOLæ¡£æ¡ˆ")
            return migrated_count
            
        except Exception as e:
            logger.error(f"KOLæ¡£æ¡ˆè¿ç§»å¤±è´¥: {e}")
            return 0
    
    def _extract_meme_mentions(self, text: str) -> List[str]:
        """æå–æ¨æ–‡ä¸­çš„memeæåŠ"""
        if not text or pd.isna(text):
            return []
        
        text = str(text).lower()
        meme_keywords = self.config['collection']['meme_keywords']
        
        mentions = []
        for keyword in meme_keywords:
            if keyword.lower() in text:
                mentions.append(keyword)
        
        return mentions
    
    def _calculate_kol_score(self, user_data: pd.Series) -> float:
        """è®¡ç®—KOLåˆ†æ•°ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        # åŸºäºç”¨æˆ·åçš„ç®€å•è¯„åˆ†
        username = str(user_data.get('username', '')).lower()
        
        score = 0.0
        
        # åŒ…å«ç‰¹å®šå…³é”®è¯åŠ åˆ†
        if any(keyword in username for keyword in ['crypto', 'btc', 'eth', 'nft']):
            score += 30
        elif any(keyword in username for keyword in ['tech', 'ai', 'startup']):
            score += 25
        elif any(keyword in username for keyword in ['trading', 'finance']):
            score += 20
        
        # ç”¨æˆ·åé•¿åº¦åŠ åˆ†ï¼ˆè¾ƒé•¿çš„ç”¨æˆ·åå¯èƒ½æ›´ä¸“ä¸šï¼‰
        if len(username) > 10:
            score += 10
        
        return min(score, 100.0)  # æœ€é«˜100åˆ†
    
    def _determine_kol_tier(self, score: float) -> str:
        """æ ¹æ®åˆ†æ•°ç¡®å®šKOLçº§åˆ«"""
        if score >= 80:
            return 'Tier 1'
        elif score >= 60:
            return 'Tier 2'
        elif score >= 40:
            return 'Tier 3'
        else:
            return 'Tier 4'
    
    def verify_migration(self):
        """éªŒè¯æ•°æ®è¿ç§»ç»“æœ"""
        print("\nğŸ” éªŒè¯æ•°æ®è¿ç§»ç»“æœ...")
        
        if not self.connect_database():
            return False
        
        try:
            cursor = self.db_conn.cursor()
            
            # æ£€æŸ¥æ¨æ–‡æ•°é‡
            cursor.execute("SELECT COUNT(*) FROM tweets")
            tweet_count = cursor.fetchone()[0]
            print(f"  æ¨æ–‡è¡¨: {tweet_count} æ¡è®°å½•")
            
            # æ£€æŸ¥ç”¨æˆ·æ•°é‡
            cursor.execute("SELECT COUNT(*) FROM kol_users")
            user_count = cursor.fetchone()[0]
            print(f"  ç”¨æˆ·è¡¨: {user_count} æ¡è®°å½•")
            
            # æ£€æŸ¥KOLåˆ†å¸ƒ
            cursor.execute("SELECT kol_tier, COUNT(*) FROM kol_users GROUP BY kol_tier ORDER BY kol_tier")
            tier_distribution = cursor.fetchall()
            print(f"  KOLçº§åˆ«åˆ†å¸ƒ:")
            for tier, count in tier_distribution:
                print(f"    {tier}: {count} ä¸ª")
            
            cursor.close()
            
            print(f"\nâœ… æ•°æ®è¿ç§»éªŒè¯å®Œæˆï¼")
            return True
            
        except Exception as e:
            logger.error(f"æ•°æ®è¿ç§»éªŒè¯å¤±è´¥: {e}")
            return False
        finally:
            if self.db_conn:
                self.db_conn.close()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ•°æ®ç®¡é“é›†æˆ...\n")
    
    try:
        integrator = DataPipelineIntegrator()
        
        # æ‰§è¡Œæ•°æ®è¿ç§»
        success = integrator.migrate_csv_data()
        
        if success:
            # éªŒè¯è¿ç§»ç»“æœ
            integrator.verify_migration()
            
            print("\nğŸ‰ æ•°æ®ç®¡é“é›†æˆå®Œæˆï¼")
            print("\nä¸‹ä¸€æ­¥æ“ä½œï¼š")
            print("1. é…ç½®Twitter API Bearer Token")
            print("2. è¿è¡Œå®æ—¶æ•°æ®é‡‡é›†æµ‹è¯•")
            print("3. éªŒè¯ç«¯åˆ°ç«¯æµç¨‹")
        else:
            print("\nâŒ æ•°æ®ç®¡é“é›†æˆå¤±è´¥")
            
    except Exception as e:
        print(f"âŒ é›†æˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")

if __name__ == "__main__":
    main()
